{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlDaj3EuoMpY",
        "outputId": "1ec49614-ba29-4582-82ee-614c9d283384"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (5.0.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: qwen_vl_utils in /usr/local/lib/python3.12/dist-packages (0.0.14)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.24.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers) (0.24.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.10.0+cu128)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: av in /usr/local/lib/python3.12/dist-packages (from qwen_vl_utils) (16.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from qwen_vl_utils) (2.32.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->qwen_vl_utils) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->qwen_vl_utils) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->qwen_vl_utils) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->qwen_vl_utils) (2026.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.9.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.0)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch>=2.0.0->accelerate) (1.3.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers) (0.24.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (8.3.1)\n",
            "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (13.9.4)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (0.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install transformers accelerate matplotlib qwen_vl_utils datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QHdw53R4oMpa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from typing import Optional, Dict, List\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "R5vTjw5aoMpc"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login(\"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\")\n",
        "\n",
        "# import os\n",
        "# os.environ[\"HF_TOKEN\"] = \"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\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from typing import Optional, List, Tuple\n",
        "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# COMPONENT 1: Learnable γ network\n",
        "# γₜ = σ(W hₜ) — học khi nào cần trust image\n",
        "# ============================================================\n",
        "class LearnableGamma(nn.Module):\n",
        "    \"\"\"\n",
        "    Học adaptive visual trust coefficient từ hidden state.\n",
        "\n",
        "    γₜ nhỏ → model tự tin vào visual evidence → tăng correction\n",
        "    γₜ lớn → token ngữ pháp → giảm correction\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_size: int):\n",
        "        super().__init__()\n",
        "        # Simple linear projection: W ∈ ℝ^(hidden_size → 1)\n",
        "        self.proj = nn.Linear(hidden_size, 1, bias=True)\n",
        "        # Init bias nhỏ để γ bắt đầu ~0.5\n",
        "        nn.init.zeros_(self.proj.weight)\n",
        "        nn.init.constant_(self.proj.bias, 0.0)\n",
        "\n",
        "    def forward(self, h_t: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            h_t: hidden state [batch, hidden_size]\n",
        "        Returns:\n",
        "            gamma: [batch, 1] ∈ (0, 1)\n",
        "        \"\"\"\n",
        "        return torch.sigmoid(self.proj(h_t))  # γₜ = σ(W hₜ)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# COMPONENT 2: Hybrid Patch + Region Encoder\n",
        "# Visual tokens = {patch tokens} ∪ {region tokens}\n",
        "# ============================================================\n",
        "class HybridVisualEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Kết hợp hai mức trừu tượng:\n",
        "    - Patch tokens: perception (texture, background, global context)\n",
        "    - Region tokens: grounding anchor (object-level semantic)\n",
        "\n",
        "    Trong Qwen2VL, patch tokens đã có sẵn trong visual_hidden_states.\n",
        "    Region tokens được tổng hợp từ patch tokens qua attention pooling.\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_size: int, num_regions: int = 16):\n",
        "        super().__init__()\n",
        "        self.num_regions = num_regions\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Learnable region query vectors (như DETR object queries)\n",
        "        # Mỗi query học cách attend vào một \"semantic region\" khác nhau\n",
        "        self.region_queries = nn.Parameter(\n",
        "            torch.randn(num_regions, hidden_size) * 0.02\n",
        "        )\n",
        "\n",
        "        # Cross-attention: region queries attend patch tokens\n",
        "        self.region_attn = nn.MultiheadAttention(\n",
        "            embed_dim=hidden_size,\n",
        "            num_heads=8,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Fusion gate: học trọng số blend patch vs region\n",
        "        self.fusion_gate = nn.Linear(hidden_size * 2, 1)\n",
        "\n",
        "    def forward(self, patch_tokens: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patch_tokens: [batch, num_patches, hidden_size]\n",
        "        Returns:\n",
        "            hybrid_tokens: [batch, num_patches + num_regions, hidden_size]\n",
        "        \"\"\"\n",
        "        batch_size = patch_tokens.shape[0]\n",
        "\n",
        "        # Expand region queries cho batch\n",
        "        queries = self.region_queries.unsqueeze(0).expand(batch_size, -1, -1)\n",
        "        # queries: [batch, num_regions, hidden_size]\n",
        "\n",
        "        # Cross-attention: region queries ← patch tokens\n",
        "        # Mỗi region query học attend vào spatial region khác nhau\n",
        "        region_tokens, _ = self.region_attn(\n",
        "            query=queries,       # [batch, num_regions, H]\n",
        "            key=patch_tokens,    # [batch, num_patches, H]\n",
        "            value=patch_tokens   # [batch, num_patches, H]\n",
        "        )\n",
        "        # region_tokens: [batch, num_regions, hidden_size]\n",
        "\n",
        "        # Concatenate: Visual tokens = patches ∪ regions\n",
        "        hybrid_tokens = torch.cat([patch_tokens, region_tokens], dim=1)\n",
        "        # [batch, num_patches + num_regions, hidden_size]\n",
        "\n",
        "        return hybrid_tokens\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# MAIN: Attention-aware M3ID với Learnable γ\n",
        "# Formula: l̂ₜ = lc + αₜ · ((1-γₜ)/γₜ) · (lc - lu)\n",
        "# ============================================================\n",
        "class HybridAttentionM3ID:\n",
        "    \"\"\"\n",
        "    Full framework:\n",
        "    1. Hybrid Patch + Region Encoder → richer visual representation\n",
        "    2. Attention-aware scaling (αₜ) → correction chỉ khi attend image\n",
        "    3. Learnable γₜ → adaptive visual trust\n",
        "\n",
        "    Decode formula:\n",
        "        l̂ₜ = lc + αₜ · ((1-γₜ)/γₜ) · (lc - lu)\n",
        "\n",
        "    So sánh với M3ID gốc:\n",
        "        l̂ₜ = lc + [indicator] · ((1-exp(-λt))/exp(-λt)) · (lc - lu)\n",
        "\n",
        "    Thay thế:\n",
        "    - exp(-λt) heuristic → γₜ = σ(W hₜ) learnable\n",
        "    - binary indicator → αₜ = attention mass (continuous)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: Qwen2_5_VLForConditionalGeneration,\n",
        "        processor: AutoProcessor,\n",
        "        hidden_size: int = 2048,       # Qwen2VL-7B hidden size is 3584 and 3B is 2048\n",
        "        num_regions: int = 16,          # số region tokens\n",
        "        gamma_lr: float = 1e-4,         # learning rate cho γ network\n",
        "        device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.processor = processor\n",
        "        self.device = device\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # === Learnable components ===\n",
        "        self.gamma_net = LearnableGamma(hidden_size).to(device=device, dtype=torch.float16)\n",
        "        self.hybrid_encoder = HybridVisualEncoder(hidden_size, num_regions).to(device=device, dtype=torch.float16)\n",
        "\n",
        "        # Optimizer chỉ cho các learnable components (không train lại LLM)\n",
        "        self.optimizer = torch.optim.Adam(\n",
        "            list(self.gamma_net.parameters()) +\n",
        "            list(self.hybrid_encoder.parameters()),\n",
        "            lr=gamma_lr\n",
        "        )\n",
        "\n",
        "    # ----------------------------------------------------------\n",
        "    # Image loading\n",
        "    # ----------------------------------------------------------\n",
        "    def load_image(self, image_source) -> Image.Image:\n",
        "      if isinstance(image_source, Image.Image):\n",
        "          return image_source\n",
        "      if isinstance(image_source, str) and image_source.startswith(('http://', 'https://')):\n",
        "          headers = {\n",
        "              \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\"\n",
        "          }\n",
        "          response = requests.get(image_source, headers=headers, timeout=10)\n",
        "          # Check HTTP status\n",
        "          response.raise_for_status()\n",
        "          # Check content type\n",
        "          content_type = response.headers.get(\"Content-Type\", \"\")\n",
        "          if \"image\" not in content_type:\n",
        "              raise ValueError(f\"URL did not return an image. Content-Type: {content_type}\")\n",
        "          return Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "      return Image.open(image_source).convert(\"RGB\")\n",
        "\n",
        "    # ----------------------------------------------------------\n",
        "    # Input preparation\n",
        "    # ----------------------------------------------------------\n",
        "    def _prepare_inputs_with_image(self, prompt: str, image: Image.Image) -> dict:\n",
        "        messages = [{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"image\", \"image\": image},\n",
        "                {\"type\": \"text\", \"text\": prompt},\n",
        "            ],\n",
        "        }]\n",
        "        text = self.processor.apply_chat_template(\n",
        "            messages, tokenize=False, add_generation_prompt=True\n",
        "        )\n",
        "        return self.processor(text=[text], images=[image], return_tensors=\"pt\", padding=True)\n",
        "\n",
        "    def _prepare_inputs_without_image(self, prompt: str) -> dict:\n",
        "        messages = [{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [{\"type\": \"text\", \"text\": prompt}],\n",
        "        }]\n",
        "        text = self.processor.apply_chat_template(\n",
        "            messages, tokenize=False, add_generation_prompt=True\n",
        "        )\n",
        "        return self.processor(text=[text], images=None, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "    # ----------------------------------------------------------\n",
        "    # COMPONENT: Tính attention mass αₜ\n",
        "    # αₜ = tổng attention weight từ text token hiện tại → image tokens\n",
        "    # ----------------------------------------------------------\n",
        "    def _compute_attention_mass(\n",
        "        self,\n",
        "        attentions: Tuple,              # tuple of [batch, heads, seq, seq]\n",
        "        num_image_tokens: int,\n",
        "        layer_idx: int = -1             # dùng layer cuối (most semantic)\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Tính αₜ = attention mass từ token cuối → image tokens.\n",
        "\n",
        "        Dùng layer attention cuối cùng vì nó capture\n",
        "        semantic-level dependencies (không phải syntactic).\n",
        "\n",
        "        Returns:\n",
        "            alpha_t: scalar tensor ∈ [0, 1]\n",
        "        \"\"\"\n",
        "        if attentions is None:\n",
        "            # Fallback: không có attention → assume moderate attention\n",
        "            return torch.tensor(0.5, device=self.device)\n",
        "\n",
        "        # Lọc ra các layer có attention weights thực sự (không phải None)\n",
        "        valid_attentions = [a for a in attentions if a is not None]\n",
        "\n",
        "        # Fallback 2: tất cả layers đều là None\n",
        "        if len(valid_attentions) == 0:\n",
        "            return torch.tensor(0.5, device=self.device)\n",
        "\n",
        "        # Lấy layer hợp lệ theo layer_idx\n",
        "        # Nếu layer_idx=-1 → lấy layer cuối trong danh sách hợp lệ\n",
        "        attn_layer = valid_attentions[layer_idx]  # [batch, heads, seq_len, seq_len]\n",
        "\n",
        "        # Attention từ token cuối (vị trí -1) đến tất cả positions\n",
        "        # Average across heads\n",
        "        attn_last_token = attn_layer[0, :, -1, :]   # [heads, seq_len]\n",
        "        attn_avg = attn_last_token.mean(dim=0)       # [seq_len]\n",
        "\n",
        "        # Image tokens nằm ở đầu sequence\n",
        "        image_start = 1\n",
        "        image_end = min(image_start + num_image_tokens, attn_avg.shape[0])\n",
        "\n",
        "        # αₜ = tổng attention mass đến image tokens\n",
        "        alpha_t = attn_avg[image_start:image_end].mean()\n",
        "\n",
        "        return alpha_t.clamp(0.0, 1.0)\n",
        "\n",
        "    # ----------------------------------------------------------\n",
        "    # GENERATE: Main decode loop\n",
        "    # ----------------------------------------------------------\n",
        "    @torch.no_grad()\n",
        "    def generate(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        image_path: str,\n",
        "        max_new_tokens: int = 100,\n",
        "        temperature: float = 0.7,\n",
        "        top_p: float = 0.9,\n",
        "        verbose: bool = True\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Decode với full framework:\n",
        "\n",
        "        Mỗi bước t:\n",
        "        1. lc = log p(yₜ | x, image)\n",
        "        2. lu = log p(yₜ | x)\n",
        "        3. αₜ = attention mass → image tokens\n",
        "        4. γₜ = σ(W hₜ) từ hidden state\n",
        "        5. l̂ₜ = lc + αₜ · ((1-γₜ)/γₜ) · (lc - lu)\n",
        "        6. Sample yₜ ~ softmax(l̂ₜ)\n",
        "        \"\"\"\n",
        "        image = self.load_image(image_path)\n",
        "\n",
        "        # Prepare inputs\n",
        "        inputs_c = self._prepare_inputs_with_image(prompt, image)\n",
        "        inputs_u = self._prepare_inputs_without_image(prompt)\n",
        "        inputs_c = {k: v.to(self.device) for k, v in inputs_c.items()}\n",
        "        inputs_u = {k: v.to(self.device) for k, v in inputs_u.items()}\n",
        "\n",
        "        # === PREFILL: lần đầu chạy cả sequence, khởi tạo KV cache ===\n",
        "        # output_attentions=True để lấy αₜ\n",
        "        outputs_c = self.model(\n",
        "            **inputs_c,\n",
        "            use_cache=True,\n",
        "            output_attentions=True,\n",
        "            output_hidden_states=True,   # cần hₜ cho γₜ\n",
        "        )\n",
        "        past_kv_c = outputs_c.past_key_values\n",
        "        logits_c   = outputs_c.logits[:, -1, :]\n",
        "\n",
        "        # Hidden state của layer cuối, token cuối → dùng cho γₜ\n",
        "        # hidden_states: tuple of [batch, seq, hidden], lấy layer cuối\n",
        "        h_t = outputs_c.hidden_states[-1][:, -1, :]  # [1, hidden_size]\n",
        "\n",
        "        # Số image tokens trong conditioned input\n",
        "        # Qwen2VL trả về image_grid_thw để tính số patch tokens\n",
        "        num_image_tokens = 0\n",
        "        if hasattr(outputs_c, 'image_grid_thw') or 'image_grid_thw' in inputs_c:\n",
        "            grid = inputs_c.get('image_grid_thw', None)\n",
        "            if grid is not None:\n",
        "                # num_patches = T * H * W (với T=1 cho ảnh tĩnh)\n",
        "                num_image_tokens = int(grid[0].prod().item())\n",
        "        # Fallback estimate\n",
        "        if num_image_tokens == 0:\n",
        "            num_image_tokens = 256  # typical for 448px image\n",
        "\n",
        "        # Tính αₜ từ prefill attention\n",
        "        alpha_attention = self._compute_attention_mass(\n",
        "            outputs_c.attentions,\n",
        "            num_image_tokens\n",
        "        )\n",
        "\n",
        "        # Unconditioned prefill (không cần attention/hidden)\n",
        "        outputs_u = self.model(**inputs_u, use_cache=True)\n",
        "        past_kv_u = outputs_u.past_key_values\n",
        "        logits_u  = outputs_u.logits[:, -1, :]\n",
        "\n",
        "        seq_len_c = inputs_c['input_ids'].shape[1]\n",
        "        seq_len_u = inputs_u['input_ids'].shape[1]\n",
        "\n",
        "        inv_temp = 1.0 / temperature\n",
        "        eos_token_id = self.processor.tokenizer.eos_token_id\n",
        "        generated_ids = []\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"\\n{'t':<4} {'α_attn':<10} {'γt':<8} {'w=(1-γ)/γ':<12} {'Token'}\")\n",
        "            print(\"-\" * 60)\n",
        "\n",
        "        # === DECODE LOOP ===\n",
        "        for t in range(1, max_new_tokens + 1):\n",
        "\n",
        "            # --- Step 4: Tính γₜ từ hidden state ---\n",
        "            # Dùng gamma_net (có thể fine-tune sau)\n",
        "            # inference_mode: tạm thời enable grad chỉ cho gamma_net\n",
        "            with torch.enable_grad():\n",
        "                h_t_input = h_t.detach().to(dtype=next(self.gamma_net.parameters()).dtype)\n",
        "                gamma_t = self.gamma_net(h_t_input)  # [1, 1]\n",
        "            gamma_t = gamma_t.detach().squeeze()         # scalar\n",
        "\n",
        "            # --- Step 2-3: Log-probs ---\n",
        "            lc = torch.log_softmax(logits_c * inv_temp, dim=-1)  # [1, vocab]\n",
        "            lu = torch.log_softmax(logits_u * inv_temp, dim=-1)  # [1, vocab]\n",
        "\n",
        "            # --- Step 5: Attention-aware M3ID formula ---\n",
        "            # l̂ₜ = lc + αₜ · ((1-γₜ)/γₜ) · (lc - lu)\n",
        "            # αₜ: continuous attention mass (thay cho binary indicator)\n",
        "            # (1-γₜ)/γₜ: learnable correction weight (thay cho heuristic)\n",
        "\n",
        "            eps = 1e-6\n",
        "            correction_weight = ((1.0 - gamma_t) / (gamma_t + eps)).clamp(0.0, 5.0)\n",
        "\n",
        "            # αₜ đóng vai trò gate: chỉ correct khi thực sự attend image\n",
        "            l_star = lc + alpha_attention * correction_weight * (lc - lu)\n",
        "            # [1, vocab]\n",
        "\n",
        "            # --- Step 6: Top-p sampling ---\n",
        "            probs = torch.softmax(l_star, dim=-1)\n",
        "\n",
        "            # Nucleus sampling\n",
        "            sorted_probs, sorted_idx = torch.sort(probs, descending=True, dim=-1)\n",
        "            cum_probs = torch.cumsum(sorted_probs, dim=-1)\n",
        "\n",
        "            mask = cum_probs > top_p\n",
        "            mask[..., 1:] = mask[..., :-1].clone()\n",
        "            mask[..., 0] = False\n",
        "\n",
        "            remove_mask = torch.zeros_like(probs, dtype=torch.bool)\n",
        "            remove_mask.scatter_(-1, sorted_idx, mask)\n",
        "            probs[remove_mask] = 0.0\n",
        "\n",
        "            prob_sum = probs.sum(dim=-1, keepdim=True).clamp(min=eps)\n",
        "            probs = probs / prob_sum\n",
        "\n",
        "            next_token_id = torch.multinomial(probs, num_samples=1)  # [1, 1]\n",
        "\n",
        "            if next_token_id.item() == eos_token_id:\n",
        "                break\n",
        "\n",
        "            generated_ids.append(next_token_id.item())\n",
        "\n",
        "            if verbose:\n",
        "                token_str = self.processor.tokenizer.decode([next_token_id.item()])\n",
        "                w_val = correction_weight.item()\n",
        "                print(f\"{t:<4} {alpha_attention.item():<10.4f} {gamma_t.item():<8.4f} {w_val:<12.4f} {repr(token_str)}\")\n",
        "\n",
        "            # === DECODE STEP: feed 1 token mới với KV cache ===\n",
        "            next_token_tensor = next_token_id.view(1, 1)\n",
        "\n",
        "            # Conditioned: cần attention + hidden state cho bước sau\n",
        "            seq_len_c += 1\n",
        "            out_c = self.model(\n",
        "                input_ids=next_token_tensor,\n",
        "                attention_mask=torch.ones((1, seq_len_c), dtype=torch.long, device=self.device),\n",
        "                past_key_values=past_kv_c,\n",
        "                use_cache=True,\n",
        "                output_attentions=True,\n",
        "                output_hidden_states=True,\n",
        "            )\n",
        "            logits_c  = out_c.logits[:, -1, :]\n",
        "            past_kv_c = out_c.past_key_values\n",
        "\n",
        "            # Cập nhật hₜ và αₜ cho bước tiếp theo\n",
        "            h_t = out_c.hidden_states[-1][:, -1, :]\n",
        "            alpha_attention = self._compute_attention_mass(\n",
        "                out_c.attentions,\n",
        "                num_image_tokens\n",
        "            )\n",
        "\n",
        "            # Unconditioned (không cần hidden/attention)\n",
        "            seq_len_u += 1\n",
        "            out_u = self.model(\n",
        "                input_ids=next_token_tensor,\n",
        "                attention_mask=torch.ones((1, seq_len_u), dtype=torch.long, device=self.device),\n",
        "                past_key_values=past_kv_u,\n",
        "                use_cache=True,\n",
        "            )\n",
        "            logits_u  = out_u.logits[:, -1, :]\n",
        "            past_kv_u = out_u.past_key_values\n",
        "\n",
        "        return self.processor.tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
        "\n",
        "    # ----------------------------------------------------------\n",
        "    # TRAINING: Fine-tune γ network + hybrid encoder\n",
        "    # Dùng khi có labeled data (response có/không hallucinate)\n",
        "    # ----------------------------------------------------------\n",
        "    def train_step(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        image_path: str,\n",
        "        target_response: str,\n",
        "        hallucination_label: float = 0.0\n",
        "    ) -> float:\n",
        "        \"\"\"\n",
        "        Fine-tune γ network với supervision đơn giản.\n",
        "        \"\"\"\n",
        "        image = self.load_image(image_path)\n",
        "\n",
        "        # 1. Chuẩn bị input có chứa cả câu hỏi và câu trả lời\n",
        "        full_text = prompt + \" \" + target_response\n",
        "        inputs_c = self._prepare_inputs_with_image(full_text, image)\n",
        "        inputs_c = {k: v.to(self.device) for k, v in inputs_c.items()}\n",
        "\n",
        "        # 2. [FIX QUAN TRỌNG] Tính chiều dài prompt PHẢI BAO GỒM CẢ ẢNH\n",
        "        # Vì ảnh sẽ chèn hàng trăm tokens <|image_pad|> vào chuỗi.\n",
        "        prompt_inputs = self._prepare_inputs_with_image(prompt, image)\n",
        "        prompt_len = prompt_inputs['input_ids'].shape[1]\n",
        "\n",
        "        # Kiểm tra an toàn: nếu câu trả lời bị tokenizer nuốt mất\n",
        "        if inputs_c['input_ids'].shape[1] <= prompt_len:\n",
        "            raise ValueError(f\"Sequence length ({inputs_c['input_ids'].shape[1]}) <= prompt_len ({prompt_len})\")\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # LLM không tính gradient\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(\n",
        "                **inputs_c,\n",
        "                output_hidden_states=True,\n",
        "                use_cache=False,\n",
        "            )\n",
        "\n",
        "        full_hidden = outputs.hidden_states[-1]  # [1, seq_len, hidden_size]\n",
        "\n",
        "        # CHỈ LẤY HIDDEN STATES CỦA CÂU TRẢ LỜI\n",
        "        response_hidden = full_hidden[:, prompt_len:, :]\n",
        "\n",
        "        # Tính γ cho các token trong câu trả lời\n",
        "        gammas = self.gamma_net(response_hidden.squeeze(0))  # [response_len, 1]\n",
        "        avg_gamma = gammas.mean()\n",
        "\n",
        "        # [FIX QUAN TRỌNG] Ép kiểu dữ liệu (dtype) khớp với avg_gamma (thường là float16)\n",
        "        # Nếu không ép, target sẽ là float32 và gây lỗi RuntimeError.\n",
        "        target_gamma = torch.tensor(\n",
        "            1.0 - hallucination_label,\n",
        "            device=self.device,\n",
        "            dtype=avg_gamma.dtype\n",
        "        )\n",
        "\n",
        "        loss = nn.functional.mse_loss(avg_gamma, target_gamma)\n",
        "\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss.item()"
      ],
      "metadata": {
        "id": "_JWy5U_adDWf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # ============================================================\n",
        "# # USAGE EXAMPLE\n",
        "# # ============================================================\n",
        "# if __name__ == \"__main__\":\n",
        "#     # Load model\n",
        "#     model_name = \"Qwen/Qwen2.5-VL-3B-Instruct\"\n",
        "\n",
        "#     processor = AutoProcessor.from_pretrained(model_name)\n",
        "#     # model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
        "#     #     model_name,\n",
        "#     #     torch_dtype=torch.float16,\n",
        "#     #     device_map=\"auto\",\n",
        "#     # )\n",
        "\n",
        "#     model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
        "#         model_name,\n",
        "#         torch_dtype=torch.float16,\n",
        "#         device_map=\"auto\",\n",
        "#         attn_implementation='eager'\n",
        "#     )\n",
        "\n",
        "#     # Khởi tạo framework\n",
        "#     framework = HybridAttentionM3ID(\n",
        "#         model=model,\n",
        "#         processor=processor,\n",
        "#         hidden_size=2048,    # Qwen2VL-7B\n",
        "#         num_regions=16,\n",
        "#         # device=\"cuda\"\n",
        "#     )\n",
        "\n",
        "#     # Inference\n",
        "#     result = framework.generate(\n",
        "#         prompt=\"Describe what you see in this image in detail.\",\n",
        "#         image_path=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/1200px-Cat03.jpg\",\n",
        "#         max_new_tokens=150,\n",
        "#         temperature=0.7,\n",
        "#         top_p=0.9,\n",
        "#         verbose=True\n",
        "#     )\n",
        "\n",
        "#     print(f\"\\n=== Generated Response ===\\n{result}\")"
      ],
      "metadata": {
        "id": "kHPQWXtIq6sw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset for training gamma"
      ],
      "metadata": {
        "id": "qWLk7WKiphAW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CprCZ_-L_4Hf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29d5272b-d639-4d16-a5cb-6c66df8be3ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.24.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (1.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.5.4)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (0.24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2026.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface-hub>=0.24.0->datasets) (0.24.0)\n",
            "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface-hub>=0.24.0->datasets) (8.3.1)\n",
            "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface-hub>=0.24.0->datasets) (13.9.4)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface-hub>=0.24.0->datasets) (0.0.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub>=0.24.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub>=0.24.0->datasets) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub>=0.24.0->datasets) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
        "\n",
        "# Giả sử framework M3ID của bạn được lưu trong file m3id.py\n",
        "# from m3id import HybridAttentionM3ID\n",
        "\n",
        "def plot_loss_curve(step_losses, save_path=\"training_loss.png\"):\n",
        "    \"\"\"\n",
        "    Hàm vẽ biểu đồ loss.\n",
        "    Vẽ loss theo từng bước (mờ) và đường trung bình trượt (rõ nét) để dễ quan sát xu hướng.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # 1. Vẽ loss gốc của từng bước (màu xanh nhạt)\n",
        "    plt.plot(step_losses, label='Step Loss', color='blue', alpha=0.3, linewidth=1)\n",
        "\n",
        "    # 2. Vẽ đường làm mượt (Moving Average) để nhìn rõ xu hướng\n",
        "    window_size = 50\n",
        "    if len(step_losses) >= window_size:\n",
        "        # Tính trung bình trượt\n",
        "        smoothed_losses = np.convolve(step_losses, np.ones(window_size)/window_size, mode='valid')\n",
        "        # Căn chỉnh trục x cho khớp\n",
        "        plt.plot(range(window_size-1, len(step_losses)), smoothed_losses,\n",
        "                 label=f'Trend (Moving Average window={window_size})', color='red', linewidth=2)\n",
        "\n",
        "    plt.title('Training Loss of Learnable Gamma (M3ID Framework)', fontsize=14)\n",
        "    plt.xlabel('Training Steps', fontsize=12)\n",
        "    plt.ylabel('MSE Loss', fontsize=12)\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Lưu ra file ảnh\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300)\n",
        "    print(f\"\\n=> Đã lưu biểu đồ loss tại: {save_path}\")\n",
        "\n",
        "    # Hiển thị biểu đồ ra màn hình (nếu chạy trên Jupyter Notebook/Colab)\n",
        "    plt.show()\n",
        "\n",
        "def train():\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    print(\"1. Loading Model...\")\n",
        "    model_name = \"Qwen/Qwen2.5-VL-3B-Instruct\"\n",
        "    processor = AutoProcessor.from_pretrained(model_name)\n",
        "    model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
        "        model_name,\n",
        "        torch_dtype=torch.float16,\n",
        "        device_map=\"auto\",\n",
        "        attn_implementation='eager' # Quan trọng để lấy được attentions\n",
        "    )\n",
        "\n",
        "    # BẮT BUỘC: Đóng băng toàn bộ LLM, chỉ train Gamma_net\n",
        "    model.requires_grad_(False)\n",
        "    model.eval()\n",
        "\n",
        "    print(\"2. Initializing Framework...\")\n",
        "    framework = HybridAttentionM3ID(\n",
        "        model=model,\n",
        "        processor=processor,\n",
        "        hidden_size=2048, # 2048 cho Qwen 3B\n",
        "        num_regions=16,\n",
        "        gamma_lr=1e-4,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    print(\"3. Loading RLHF-V Dataset...\")\n",
        "    dataset = load_dataset(\"openbmb/RLHF-V-Dataset\", split=\"train\")\n",
        "\n",
        "    # Lấy 1000 mẫu để train nhanh nghiệm thu thuật toán\n",
        "    train_data = dataset.select(range(1000))\n",
        "\n",
        "    epochs = 2\n",
        "\n",
        "    # --- BIẾN LƯU TRỮ LOSS ĐỂ VẼ BIỂU ĐỒ ---\n",
        "    history_step_losses = []\n",
        "\n",
        "    print(f\"4. Starting Training for {epochs} epochs...\")\n",
        "    framework.gamma_net.train() # Bật chế độ train cho mạng Gamma\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        valid_steps = 0\n",
        "\n",
        "        progress_bar = tqdm(train_data, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        for item in progress_bar:\n",
        "            try:\n",
        "                image = item['image']\n",
        "\n",
        "                # Bóc tách text_data\n",
        "                text_data = item.get('text', item) # Đề phòng dataset format bị đổi\n",
        "                if isinstance(text_data, str):\n",
        "                    text_data = json.loads(text_data)\n",
        "\n",
        "                prompt = text_data.get('question', '')\n",
        "                chosen_response = text_data.get('chosen', '')\n",
        "                rejected_response = text_data.get('rejected', '')\n",
        "\n",
        "                if not prompt or not chosen_response or not rejected_response:\n",
        "                    continue # Bỏ qua nếu data bị thiếu field\n",
        "\n",
        "                # 1. Câu đúng (không ảo giác) -> target gamma cao (ít correction)\n",
        "                loss_chosen = framework.train_step(\n",
        "                    prompt=prompt,\n",
        "                    image_path=image,\n",
        "                    target_response=chosen_response,\n",
        "                    hallucination_label=0.0\n",
        "                )\n",
        "\n",
        "                # 2. Câu ảo giác -> target gamma thấp (ép correction mạnh)\n",
        "                loss_rejected = framework.train_step(\n",
        "                    prompt=prompt,\n",
        "                    image_path=image,\n",
        "                    target_response=rejected_response,\n",
        "                    hallucination_label=1.0\n",
        "                )\n",
        "\n",
        "                # Trung bình loss của cả 2 nhánh\n",
        "                step_loss = (loss_chosen + loss_rejected) / 2.0\n",
        "\n",
        "                # LƯU LOSS VÀO LIST ĐỂ TÍ VẼ\n",
        "                history_step_losses.append(step_loss)\n",
        "\n",
        "                total_loss += step_loss\n",
        "                valid_steps += 1\n",
        "\n",
        "                progress_bar.set_postfix({\"Avg Loss\": f\"{total_loss/valid_steps:.4f}\"})\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"\\n[Cảnh báo] Bỏ qua sample do lỗi: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        epoch_avg = total_loss / max(1, valid_steps)\n",
        "        print(f\"\\n=> End of Epoch {epoch+1} | Mean Epoch Loss: {epoch_avg:.4f}\")\n",
        "\n",
        "        # LƯU TRỌNG SỐ\n",
        "        save_path = f\"gamma_net_epoch_{epoch+1}.pt\"\n",
        "        torch.save(framework.gamma_net.state_dict(), save_path)\n",
        "        print(f\"=> Saved Checkpoint to {save_path}\\n\")\n",
        "\n",
        "    # 5. KẾT THÚC HUẤN LUYỆN -> VẼ BIỂU ĐỒ\n",
        "    print(\"5. Generating Loss Curve...\")\n",
        "    plot_loss_curve(history_step_losses, save_path=\"gamma_training_loss.png\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376,
          "referenced_widgets": [
            "235596b840d64e93bb8c1af22cc63f56",
            "fcbe0cc5649a4497aa982bb0db9eb815",
            "068fde2e019d4af692ed106b4c8a8042",
            "ca5c0d5548134ae0a4b6e289a6502796",
            "dc17e439da60414b82a84a35a02ab859",
            "144bd128c1024350b816ef02df5335c1",
            "843033efed1e4613b983204a24d1e314",
            "6a37d61e1f6441aa913006935428e7c8",
            "89e711f3c14344f29b32b12c8eed036d",
            "0cc6d16896e94736a6ebae7f31daa6a5",
            "c295c2ef9c124d81a2336f446bc1c65b",
            "ae5ca1a0b3094492acfa7a065c3e066e",
            "3d2451cbaf0445a0b417218e68950241",
            "8a2199f865d24060888cde912b26687f",
            "738a16eeecb54f4087373f3c1ce69dca",
            "e608fea47a7a4cb383620ef4f34f23e4",
            "695b8951c51b45aeabb723646bba5569",
            "55711491fdf84300b15bcc3195b07800",
            "748d64f0d73b49c98bf0816006113e04",
            "c329999876b24a07b8151e6ca472479b",
            "033d40cc66fc44a995f9c6b1fc33537b",
            "4423818e9b6c45c9bd8065abfda1b800",
            "699c90ae7cff4939bc725fcd3acdb3af",
            "48f5e8f3fe114ea081eb2b9b04f25c1a",
            "ad0bce9553724d9b824c149ebebf17a7",
            "31dc6353c149424ca1870d6c17112a5e",
            "a97f41eadddc4225a1dd50bcd25a2ee4",
            "0f23005dd1304f2da6b318879f725eae",
            "14baf0a8fbbd47f7b4c231cfebee85a4",
            "b451d725836e417896922882e908c5b3",
            "57e0148bf3684557b203fbbec75fb7ef",
            "075558700cd145048c219f2b87ed1553",
            "85a59ecd1ca8411cb5a231b194557e90"
          ]
        },
        "id": "9hiNIZpU0ZUn",
        "outputId": "e6c72580-cd4c-45d0-d399-383e0310491f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Loading Model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "235596b840d64e93bb8c1af22cc63f56"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae5ca1a0b3094492acfa7a065c3e066e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/824 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "699c90ae7cff4939bc725fcd3acdb3af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2. Initializing Framework...\n",
            "3. Loading RLHF-V Dataset...\n",
            "4. Starting Training for 2 epochs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:   4%|▍         | 39/1000 [00:45<14:18,  1.12it/s, Avg Loss=nan]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Cảnh báo] Bỏ qua sample do lỗi: CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacity of 14.56 GiB of which 1.70 GiB is free. Including non-PyTorch memory, this process has 12.87 GiB memory in use. Of the allocated memory 12.65 GiB is allocated by PyTorch, and 81.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:   9%|▉         | 91/1000 [01:57<23:13,  1.53s/it, Avg Loss=nan]"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 857191,
          "sourceId": 1462296,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 9364369,
          "sourceId": 14658640,
          "sourceType": "datasetVersion"
        }
      ],
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "235596b840d64e93bb8c1af22cc63f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fcbe0cc5649a4497aa982bb0db9eb815",
              "IPY_MODEL_068fde2e019d4af692ed106b4c8a8042",
              "IPY_MODEL_ca5c0d5548134ae0a4b6e289a6502796"
            ],
            "layout": "IPY_MODEL_dc17e439da60414b82a84a35a02ab859"
          }
        },
        "fcbe0cc5649a4497aa982bb0db9eb815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_144bd128c1024350b816ef02df5335c1",
            "placeholder": "​",
            "style": "IPY_MODEL_843033efed1e4613b983204a24d1e314",
            "value": "Download complete: "
          }
        },
        "068fde2e019d4af692ed106b4c8a8042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a37d61e1f6441aa913006935428e7c8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89e711f3c14344f29b32b12c8eed036d",
            "value": 0
          }
        },
        "ca5c0d5548134ae0a4b6e289a6502796": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cc6d16896e94736a6ebae7f31daa6a5",
            "placeholder": "​",
            "style": "IPY_MODEL_c295c2ef9c124d81a2336f446bc1c65b",
            "value": " 0.00/0.00 [00:00&lt;?, ?B/s]"
          }
        },
        "dc17e439da60414b82a84a35a02ab859": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "144bd128c1024350b816ef02df5335c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "843033efed1e4613b983204a24d1e314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a37d61e1f6441aa913006935428e7c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "89e711f3c14344f29b32b12c8eed036d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0cc6d16896e94736a6ebae7f31daa6a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c295c2ef9c124d81a2336f446bc1c65b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae5ca1a0b3094492acfa7a065c3e066e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d2451cbaf0445a0b417218e68950241",
              "IPY_MODEL_8a2199f865d24060888cde912b26687f",
              "IPY_MODEL_738a16eeecb54f4087373f3c1ce69dca"
            ],
            "layout": "IPY_MODEL_e608fea47a7a4cb383620ef4f34f23e4"
          }
        },
        "3d2451cbaf0445a0b417218e68950241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_695b8951c51b45aeabb723646bba5569",
            "placeholder": "​",
            "style": "IPY_MODEL_55711491fdf84300b15bcc3195b07800",
            "value": "Fetching 2 files: 100%"
          }
        },
        "8a2199f865d24060888cde912b26687f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_748d64f0d73b49c98bf0816006113e04",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c329999876b24a07b8151e6ca472479b",
            "value": 2
          }
        },
        "738a16eeecb54f4087373f3c1ce69dca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_033d40cc66fc44a995f9c6b1fc33537b",
            "placeholder": "​",
            "style": "IPY_MODEL_4423818e9b6c45c9bd8065abfda1b800",
            "value": " 2/2 [00:00&lt;00:00, 50.24it/s]"
          }
        },
        "e608fea47a7a4cb383620ef4f34f23e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "695b8951c51b45aeabb723646bba5569": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55711491fdf84300b15bcc3195b07800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "748d64f0d73b49c98bf0816006113e04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c329999876b24a07b8151e6ca472479b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "033d40cc66fc44a995f9c6b1fc33537b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4423818e9b6c45c9bd8065abfda1b800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "699c90ae7cff4939bc725fcd3acdb3af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48f5e8f3fe114ea081eb2b9b04f25c1a",
              "IPY_MODEL_ad0bce9553724d9b824c149ebebf17a7",
              "IPY_MODEL_31dc6353c149424ca1870d6c17112a5e"
            ],
            "layout": "IPY_MODEL_a97f41eadddc4225a1dd50bcd25a2ee4"
          }
        },
        "48f5e8f3fe114ea081eb2b9b04f25c1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f23005dd1304f2da6b318879f725eae",
            "placeholder": "​",
            "style": "IPY_MODEL_14baf0a8fbbd47f7b4c231cfebee85a4",
            "value": "Loading weights: 100%"
          }
        },
        "ad0bce9553724d9b824c149ebebf17a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b451d725836e417896922882e908c5b3",
            "max": 824,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57e0148bf3684557b203fbbec75fb7ef",
            "value": 824
          }
        },
        "31dc6353c149424ca1870d6c17112a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_075558700cd145048c219f2b87ed1553",
            "placeholder": "​",
            "style": "IPY_MODEL_85a59ecd1ca8411cb5a231b194557e90",
            "value": " 824/824 [00:36&lt;00:00, 45.97it/s, Materializing param=model.visual.patch_embed.proj.weight]"
          }
        },
        "a97f41eadddc4225a1dd50bcd25a2ee4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f23005dd1304f2da6b318879f725eae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14baf0a8fbbd47f7b4c231cfebee85a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b451d725836e417896922882e908c5b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57e0148bf3684557b203fbbec75fb7ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "075558700cd145048c219f2b87ed1553": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85a59ecd1ca8411cb5a231b194557e90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}