{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eb6c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install transformers accelerate matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d3c752",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcc679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"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\")\n",
    "\n",
    "# import os\n",
    "# os.environ[\"HF_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689b7a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "\n",
    "model_id = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "\n",
    "tokenizer = AutoProcessor.from_pretrained(model_id)\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_id,\n",
    "    dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa35f071",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f7c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p coco/annotations\n",
    "!mkdir -p coco/val2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413c28cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Downloading annotations...\")\n",
    "!wget -c http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n",
    "!unzip -q annotations_trainval2014.zip -d coco/\n",
    "!rm annotations_trainval2014.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61237361",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Downloading images...\")\n",
    "!wget -c http://images.cocodataset.org/zips/val2014.zip\n",
    "!unzip -q val2014.zip -d coco/\n",
    "!rm val2014.zip\n",
    "\n",
    "print(\"Done! Dữ liệu đã sẵn sàng tại thư mục /content/coco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebc092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "ann_path = '/content/coco/annotations/instances_val2014.json'\n",
    "img_dir = '/content/coco/val2014'\n",
    "\n",
    "with open(ann_path, 'r') as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "dataset_for_inference = []\n",
    "\n",
    "# Lấy 500 ảnh ngẫu nhiên\n",
    "random_images = random.sample(coco_data['images'], 500)\n",
    "\n",
    "for img_info in random_images:\n",
    "    dataset_for_inference.append({\n",
    "        \"image_id\": img_info['id'],\n",
    "        \"image_path\": f\"{img_dir}/{img_info['file_name']}\",\n",
    "        \"prompt\": \"Describe the image.\"\n",
    "    })\n",
    "\n",
    "print(f\"Đã chuẩn bị {len(dataset_for_inference)} ảnh ngẫu nhiên để test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693e9cc5",
   "metadata": {},
   "source": [
    "## Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57de0f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def infer_one(model, processor, sample, device=\"cuda\"):\n",
    "\n",
    "    question = sample['question']\n",
    "    image = sample['image']\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\"},\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": (\n",
    "                        f\"Question: {question}\"\n",
    "                    )\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    text = processor.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    inputs = processor(\n",
    "        images=image,\n",
    "        text=text,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=200,\n",
    "            do_sample=False\n",
    "        )\n",
    "\n",
    "    output_text = processor.decode(\n",
    "        output_ids[0],\n",
    "        skip_special_tokens=True\n",
    "    ).lower()\n",
    "\n",
    "    # if re.search(r\"\\byes\\b\", output_text):\n",
    "    #     answer = \"yes\"\n",
    "    # elif re.search(r\"\\bno\\b\", output_text):\n",
    "    #     answer = \"no\"\n",
    "    # else:\n",
    "    #     answer = \"no\"\n",
    "\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"answer\": output_text\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10740525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def infer_all(model, dataset_list, save_path):\n",
    "    \"\"\"\n",
    "    dataset_list: Danh sách các dict, mỗi dict có:\n",
    "        {\"image_id\": int, \"image_path\": str, \"prompt\": str}\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "\n",
    "    # Nếu file đã tồn tại, có thể load lên để chạy tiếp (resume) nếu muốn\n",
    "    if os.path.exists(save_path):\n",
    "        with open(save_path, 'r') as f:\n",
    "            all_results = json.load(f)\n",
    "        print(f\"Resuming from {len(all_results)} images...\")\n",
    "\n",
    "    # Lọc ra những ảnh chưa chạy (nếu bạn muốn hỗ trợ resume)\n",
    "    processed_ids = {res['image_id'] for res in all_results}\n",
    "\n",
    "    for item in tqdm(dataset_list):\n",
    "        img_id = item['image_id']\n",
    "        if img_id in processed_ids:\n",
    "            continue\n",
    "\n",
    "        img_path = item['image_path']\n",
    "        prompt = item['prompt']\n",
    "\n",
    "        try:\n",
    "            # # Gọi hàm generate từ class M3ID_Paper của bạn\n",
    "            # output_caption = m3id_engine.generate(\n",
    "            #     prompt=prompt,\n",
    "            #     image_path=img_path,\n",
    "            #     max_new_tokens=100, # Caption thường ngắn, 100 là đủ\n",
    "            #     temperature=0.2,\n",
    "            #     verbose=False\n",
    "            # )\n",
    "            image = tokenizer.decode_image(img_path)\n",
    "            output_caption = infer_one(\n",
    "                model,\n",
    "                tokenizer,\n",
    "                {\n",
    "                    \"question\": prompt,\n",
    "                    \"image\": image,\n",
    "                },\n",
    "                device=\"cuda\"\n",
    "            )['answer']\n",
    "\n",
    "            # Lưu kết quả\n",
    "            res_entry = {\n",
    "                \"image_id\": img_id,\n",
    "                \"caption\": output_caption,\n",
    "                \"prompt\": prompt # Lưu lại prompt để đối chiếu nếu cần\n",
    "            }\n",
    "            all_results.append(res_entry)\n",
    "\n",
    "            # Lưu định kỳ mỗi 50 ảnh để tránh mất dữ liệu nếu crash\n",
    "            if len(all_results) % 50 == 0:\n",
    "                with open(save_path, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(all_results, f, indent=4)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi tại ảnh {img_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Lưu file cuối cùng\n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_results, f, indent=4)\n",
    "\n",
    "    print(f\"Đã lưu toàn bộ {len(all_results)} kết quả vào {save_path}\")\n",
    "    return all_results\n",
    "\n",
    "# --- CÁCH SỬ DỤNG ---\n",
    "# Giả sử bạn có list ảnh từ MSCOCO\n",
    "# my_test_data = [\n",
    "#    {\"image_id\": 391895, \"image_path\": \"val2014/COCO_val2014_000000391895.jpg\", \"prompt\": \"Please describe this image in detail.\"},\n",
    "#    ...\n",
    "# ]\n",
    "\n",
    "# run_hallucination_benchmark(m3id, my_test_data, \"m3id_results_coco.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3451ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = \"m3id_results_coco_val.json\"\n",
    "\n",
    "results = infer_all(\n",
    "    model=model,\n",
    "    dataset_list=dataset_for_inference,\n",
    "    save_path=save_file\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
