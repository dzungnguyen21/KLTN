{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook ran on RTX 4090: 24 VRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/venv/main/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /venv/main/lib/python3.12/site-packages (3.0.0)\n",
      "Requirement already satisfied: datasets in /venv/main/lib/python3.12/site-packages (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /venv/main/lib/python3.12/site-packages (from pandas) (2.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /venv/main/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: filelock in /venv/main/lib/python3.12/site-packages (from datasets) (3.20.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /venv/main/lib/python3.12/site-packages (from datasets) (23.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /venv/main/lib/python3.12/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /venv/main/lib/python3.12/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /venv/main/lib/python3.12/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /venv/main/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /venv/main/lib/python3.12/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /venv/main/lib/python3.12/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /venv/main/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /venv/main/lib/python3.12/site-packages (from datasets) (1.3.4)\n",
      "Requirement already satisfied: packaging in /venv/main/lib/python3.12/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /venv/main/lib/python3.12/site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /venv/main/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.3)\n",
      "Requirement already satisfied: anyio in /venv/main/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
      "Requirement already satisfied: certifi in /venv/main/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /venv/main/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /venv/main/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /venv/main/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /venv/main/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: shellingham in /venv/main/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /venv/main/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (0.21.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /venv/main/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /venv/main/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /venv/main/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /venv/main/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /venv/main/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /venv/main/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /venv/main/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /venv/main/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /venv/main/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /venv/main/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/main/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.6.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /venv/main/lib/python3.12/site-packages (from typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (8.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install pandas datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train, val, test = load_dataset(\"HuggingFaceM4/ChartQA\", split=[\"train\", \"val\", \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'query', 'label', 'human_or_machine'],\n",
       "    num_rows: 2500\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark QwenVL before finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /venv/main/lib/python3.12/site-packages (5.0.0)\n",
      "Requirement already satisfied: accelerate in /venv/main/lib/python3.12/site-packages (1.12.0)\n",
      "Requirement already satisfied: pillow in /venv/main/lib/python3.12/site-packages (12.1.0)\n",
      "Requirement already satisfied: sentencepiece in /venv/main/lib/python3.12/site-packages (0.2.1)\n",
      "Requirement already satisfied: filelock in /venv/main/lib/python3.12/site-packages (from transformers) (3.20.1)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /venv/main/lib/python3.12/site-packages (from transformers) (1.3.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /venv/main/lib/python3.12/site-packages (from transformers) (2.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /venv/main/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /venv/main/lib/python3.12/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /venv/main/lib/python3.12/site-packages (from transformers) (2026.1.15)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /venv/main/lib/python3.12/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in /venv/main/lib/python3.12/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /venv/main/lib/python3.12/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /venv/main/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /venv/main/lib/python3.12/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /venv/main/lib/python3.12/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /venv/main/lib/python3.12/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /venv/main/lib/python3.12/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /venv/main/lib/python3.12/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: anyio in /venv/main/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.12.0)\n",
      "Requirement already satisfied: certifi in /venv/main/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /venv/main/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
      "Requirement already satisfied: idna in /venv/main/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /venv/main/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
      "Requirement already satisfied: psutil in /venv/main/lib/python3.12/site-packages (from accelerate) (7.2.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /venv/main/lib/python3.12/site-packages (from accelerate) (2.10.0+cu126)\n",
      "Requirement already satisfied: setuptools in /venv/main/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /venv/main/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /venv/main/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /venv/main/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in /venv/main/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /venv/main/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /venv/main/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /venv/main/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /venv/main/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /venv/main/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /venv/main/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /venv/main/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /venv/main/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /venv/main/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /venv/main/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /venv/main/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /venv/main/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /venv/main/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /venv/main/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /venv/main/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.6.0 in /venv/main/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.6.0)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /venv/main/lib/python3.12/site-packages (from cuda-bindings==12.9.4->torch>=2.0.0->accelerate) (1.3.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /venv/main/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /venv/main/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /venv/main/lib/python3.12/site-packages (from typer-slim->transformers) (8.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install transformers accelerate pillow sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63a118cc7f643debda15c9acfe3ea90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/729 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Qwen2_5_VLForConditionalGeneration(\n",
       "  (model): Qwen2_5_VLModel(\n",
       "    (visual): Qwen2_5_VisionTransformerPretrainedModel(\n",
       "      (patch_embed): Qwen2_5_VisionPatchEmbed(\n",
       "        (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n",
       "      )\n",
       "      (rotary_pos_emb): Qwen2_5_VisionRotaryEmbedding()\n",
       "      (blocks): ModuleList(\n",
       "        (0-31): 32 x Qwen2_5_VLVisionBlock(\n",
       "          (norm1): Qwen2RMSNorm((1280,), eps=1e-06)\n",
       "          (norm2): Qwen2RMSNorm((1280,), eps=1e-06)\n",
       "          (attn): Qwen2_5_VLVisionAttention(\n",
       "            (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "            (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (mlp): Qwen2_5_VLMLP(\n",
       "            (gate_proj): Linear(in_features=1280, out_features=3420, bias=True)\n",
       "            (up_proj): Linear(in_features=1280, out_features=3420, bias=True)\n",
       "            (down_proj): Linear(in_features=3420, out_features=1280, bias=True)\n",
       "            (act_fn): SiLUActivation()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (merger): Qwen2_5_VLPatchMerger(\n",
       "        (ln_q): Qwen2RMSNorm((1280,), eps=1e-06)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=5120, out_features=5120, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=5120, out_features=3584, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (language_model): Qwen2_5_VLTextModel(\n",
       "      (embed_tokens): Embedding(152064, 3584)\n",
       "      (layers): ModuleList(\n",
       "        (0-27): 28 x Qwen2_5_VLDecoderLayer(\n",
       "          (self_attn): Qwen2_5_VLAttention(\n",
       "            (q_proj): Linear(in_features=3584, out_features=3584, bias=True)\n",
       "            (k_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
       "            (o_proj): Linear(in_features=3584, out_features=3584, bias=False)\n",
       "          )\n",
       "          (mlp): Qwen2MLP(\n",
       "            (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "            (up_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "            (down_proj): Linear(in_features=18944, out_features=3584, bias=False)\n",
       "            (act_fn): SiLUActivation()\n",
       "          )\n",
       "          (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "          (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "        )\n",
       "      )\n",
       "      (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "      (rotary_emb): Qwen2_5_VLRotaryEmbedding()\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "\n",
    "model_id = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_id,\n",
    "    dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_one(sample):\n",
    "    img = sample['image']\n",
    "    question = sample['query']\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": img},\n",
    "                {\"type\": \"text\", \"text\": question}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    text = processor.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    inputs = processor(\n",
    "        text = text,\n",
    "        images = img,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=64\n",
    "        )\n",
    "\n",
    "    pred = processor.decode(output[0], skip_special_tokens=True)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# test_subset = test.select(range(10))\n",
    "\n",
    "# results = []\n",
    "# for sample in tqdm(test_subset, desc=\"Benchmarking\", total=len(test_subset)):\n",
    "#     pred = infer_one(sample)\n",
    "#     results.append({\n",
    "#         \"pred\": pred,\n",
    "#         \"gt\": sample[\"query\"]\n",
    "#     })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_number(text):\n",
    "    if text is None:\n",
    "        return None\n",
    "    nums = re.findall(r\"-?\\d+\\.?\\d*\", text)\n",
    "    if len(nums) == 0:\n",
    "        return None\n",
    "    try:\n",
    "        return float(nums[0])\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Infer test set: 100%|██████████| 2500/2500 [1:11:15<00:00,  1.71s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "out_path = \"chartqa_qwenvl_test_predictions.jsonl\"\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_grad_enabled(False)\n",
    "model.eval()\n",
    "\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for idx, sample in enumerate(\n",
    "        tqdm(test, desc=\"Infer test set\") ## Sửa ở đây để infer full hoặc subset. test(full) và test_subset(infer một phần)\n",
    "    ):\n",
    "        pred_text = infer_one(sample)\n",
    "\n",
    "        record = {\n",
    "            \"idx\": idx,\n",
    "            \"query\": sample[\"query\"],\n",
    "            \"pred_text\": pred_text,\n",
    "            \"pred_num\": extract_number(pred_text),\n",
    "            \"gts\": sample[\"label\"],                 # list\n",
    "            \"human_or_machine\": sample[\"human_or_machine\"]\n",
    "        }\n",
    "\n",
    "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "        # optional: tránh GPU chậm dần\n",
    "        if idx % 50 == 0:\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_prediction(pred_text: str):\n",
    "    if pred_text is None:\n",
    "        return \"\"\n",
    "\n",
    "    # lấy phần sau \"assistant\"\n",
    "    if \"assistant\" in pred_text:\n",
    "        pred_text = pred_text.split(\"assistant\", 1)[-1]\n",
    "\n",
    "    # strip whitespace\n",
    "    return pred_text.strip()\n",
    "\n",
    "def extract_number(text):\n",
    "    nums = re.findall(r\"-?\\d+\\.?\\d*\", text)\n",
    "    if len(nums) == 0:\n",
    "        return None\n",
    "    try:\n",
    "        return float(nums[0])\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_answer_type(gt: str):\n",
    "    gt = gt.strip().lower()\n",
    "\n",
    "    if gt in [\"yes\", \"no\"]:\n",
    "        return \"boolean\"\n",
    "\n",
    "    try:\n",
    "        float(gt)\n",
    "        return \"numeric\"\n",
    "    except:\n",
    "        return \"string\"\n",
    "\n",
    "def evaluate_sample(pred_text, gt):\n",
    "    pred_text = clean_prediction(pred_text)\n",
    "    answer_type = get_answer_type(gt)\n",
    "\n",
    "    # YES / NO\n",
    "    if answer_type == \"boolean\":\n",
    "        pred = pred_text.lower()\n",
    "        if \"yes\" in pred:\n",
    "            return gt.lower() == \"yes\"\n",
    "        if \"no\" in pred:\n",
    "            return gt.lower() == \"no\"\n",
    "        return False\n",
    "\n",
    "    # NUMERIC\n",
    "    if answer_type == \"numeric\":\n",
    "        pred_num = extract_number(pred_text)\n",
    "        gt_num = float(gt)\n",
    "\n",
    "        if pred_num is None:\n",
    "            return False\n",
    "\n",
    "        # exact match\n",
    "        if pred_num == gt_num:\n",
    "            return True\n",
    "\n",
    "        # relaxed (5%)\n",
    "        if abs(pred_num - gt_num) / max(1.0, abs(gt_num)) <= 0.05:\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    # STRING\n",
    "    pred = pred_text.lower()\n",
    "    gt = gt.lower()\n",
    "\n",
    "    return gt in pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_jsonl(path):\n",
    "    records = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            records.append(json.loads(line))\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_record(record):\n",
    "    pred_text = record[\"pred_text\"]\n",
    "    gts = record[\"gts\"]  # list\n",
    "\n",
    "    for gt in gts:\n",
    "        if evaluate_sample(pred_text, gt):\n",
    "            return True\n",
    "    return False\n",
    "def benchmark_jsonl(path):\n",
    "    records = load_jsonl(path)\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    # optional: breakdown theo loại\n",
    "    stats = {\n",
    "        \"boolean\": {\"correct\": 0, \"total\": 0},\n",
    "        \"numeric\": {\"correct\": 0, \"total\": 0},\n",
    "        \"string\": {\"correct\": 0, \"total\": 0},\n",
    "    }\n",
    "\n",
    "    for rec in records:\n",
    "        total += 1\n",
    "        is_correct = evaluate_record(rec)\n",
    "        if is_correct:\n",
    "            correct += 1\n",
    "\n",
    "        # thống kê theo loại answer (dựa trên GT đầu tiên)\n",
    "        gt0 = rec[\"gts\"][0]\n",
    "        ans_type = get_answer_type(gt0)\n",
    "        stats[ans_type][\"total\"] += 1\n",
    "        if is_correct:\n",
    "            stats[ans_type][\"correct\"] += 1\n",
    "\n",
    "    acc = correct / total if total > 0 else 0.0\n",
    "    return acc, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, stats = benchmark_jsonl(\"predictions.jsonl\")\n",
    "\n",
    "print(f\"Overall Accuracy: {acc:.4f}\")\n",
    "\n",
    "for k, v in stats.items():\n",
    "    if v[\"total\"] > 0:\n",
    "        print(f\"{k}: {v['correct']}/{v['total']} = {v['correct']/v['total']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9344738,
     "sourceId": 14628980,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
